import json

import numpy as np
import torch
import time
from torch.profiler import profile, record_function, ProfilerActivity

torch.backends.quantized.engine = 'qnnpack'
# 加载 TorchScript 模型
model = torch.jit.load('/Users/minim4/syncGN/mmoe_pairwise/model_pt/gn/model_pairwise_weekly_nondcn.pt')

# 设置为评估模式
model.eval()

# 准备输入数据（确保与 tracing 时的输入形状一致）
# inputs = torch.randn(1, 3, 224, 224)  # 替换为你的输入形状
# inputs = [[4,13,24,28,36,40,42,7,16,20,16,18,15,13,6,13,18,21,27,32,34,1,6,13,15,23,30,33,0,1,5,7,13,19,22,0,1,5,6,11,17,19,1,3,6,9,12,16,17,5,10,15,13,14,16,14,0,4,12,21,29,35,38,0,5,18,26,36,45,47,5,9,11,13,15,19,20,5,7,13,15,17,19,20,1,41,50,55,59,62,64,21,42,51,56,59,63,65,39,53,64,68,71,73,75,3,6,7,8,8,7,8,7,6,23,15,38,20,45,18,51,18,56,15,58,13,20,25,35,24,46,24,55,22,63,23,66,19,67,20,36,22,56,20,69,26,77,29,83,25,84,19,86,15,15,19,23,18,26,18,31,17,34,16,39,14,42,12,34,18,53,14,66,21,73,22,76,18,77,15,79,12,21,10,43,20,56,28,59,24,60,23,61,19,62,16,39,33,53,29,61,30,65,27,70,29,70,25,72,25,38,27,57,23,70,32,78,33,83,27,85,21,87,19,35,25,45,24,49,21,53,21,55,22,59,18,63,16,35,22,55,18,67,26,73,29,76,23,78,19,80,16,3,7,11,21,21,24,29,28,38,29,45,30,48,27,9,31,19,29,29,30,39,40,48,46,54,43,57,41,29,16,58,34,67,17,75,17,82,16,85,18,87,20,6,15,10,17,14,21,18,25,21,25,25,22,28,20,32,13,60,29,66,12,73,13,76,10,78,11,80,13,11,22,29,38,44,51,55,2,9,18,27,37,47,53,1,2,8,14,23,33,39,1,2,7,11,19,29,35,2,5,9,14,19,26,30,8,20,27,38,36,48,54,6,6,19,26,35,47,44,7,9,22,27,39,52,57,8,12,16,21,26,32,36,6,11,14,16,18,20,21,6,43,55,60,63,67,69,22,46,57,61,64,67,69,47,65,69,73,76,79,80,5,7,8,12,16,21,23,11,22,29,38,44,50,53,2,9,18,27,38,48,51,1,2,8,14,23,33,38,1,2,7,11,19,29,34,2,5,8,14,19,25,29,8,17,18,21,28,27,17,7,7,19,27,34,45,46,7,9,23,29,38,47,54,8,12,15,21,26,31,35,6,12,14,16,19,21,22,8,44,57,61,64,67,69,23,45,58,62,65,68,70,46,65,70,73,76,79,80,3,7,7,10,13,14,11,3,6,8,13,20,33,40,2,5,6,10,17,30,39,1,2,3,4,7,16,25,1,2,2,3,6,15,24,1,1,1,2,6,14,21,4,6,6,7,10,16,22,3,9,14,15,22,45,37,4,10,14,16,26,41,48,1,3,3,5,9,18,25,3,4,4,11,14,16,17,0,28,31,45,51,56,58,14,28,34,45,52,56,59,19,25,23,55,64,69,71,1,2,2,4,7,11,19,9,12,15,18,1,3,7,9,53,63,66,69,50,61,65,69,13,16,18,20,9,15,24,39,18,31,41,50,4,8,16,31,20,34,46,55,23,31,39,46,13,17,22,27,59,69,77,80,38,35,37,32,38,39,47,50,2,8,16,26,75,83,87,89,42,13,0,66,67,5,2,45,1,4,1,1,44,66,57,56,50,40,35,33,32,29,11,81,82,63,61,57,62,67,63,57,65,67,67,64,56,48,46,45,41,15,84,82,61,59,55,62,65,64,46,42,39,37,33,33,31,28,29,15,4,4,60,53,47,46,43,42,42,37,39,36,34,32,29,29,8,9,15,18,21,15,18,19,10,13,13,15,16,18,14,16,17,17,18,21,12,12,14,14,15,19,64,67,65,68,67,72,72,77,69,67,66,64,69,67,66,65,45,33,33,20,44,24,22,8,63,62,61,59,93,90,90,88,83,82,82,80,67,69,70,68,94,92,89,86,84,82,82,81,87,87,87,87,76,79,83,84,85,84,84,84,95,94,91,88,94,93,93,92,81,84,88,89,94,93,91,88,1,29600,45434,20464,20406,4206,56220,12617,16320,36608,46499,21950,20108,21950,21950,23800,15628,18289,22793,18980,18980,8,8,82,8,82,8,8,8,8,8,3,3,3,4,4,4,3,4,3,3,4,8,5,6,11,10,8,10,8,10,1223,499,971,74,584,877,977,351,249,584,499,349,971,1223,678,0,849,971,296,916,383,994,424,1130,1236,439,349,1078,584,1015,1130,1058,852,1049,1104,75,499,525,1223,0,932,971,729,1223,332,1130,727,884,584,727,1019,499,1154,1067,932,349,598,1067,932,916,62,1223,1019,347,932,499,335,584,8,971,349,0,1019,584,1067,932,349,351,1223,0,22833,21034,33340,40181,43305,52945,32578,34174,30398,39086,11048,13315,11269,9307,20850,14848,6645,13694,11048,14749,8,82,82,102,82,8,82,88,8,8,4,4,4,4,4,4,4,2,4,4,8,8,8,10,8,10,11,1,8,8,877,884,977,252,349,1019,390,690,332,727,916,1223,877,296,813,971,1223,729,877,0,0,0,0,0,1223,439,1085,1049,252,1078,932,0,1223,971,296,276,249,595,1067,412,1223,439,849,584,1078,1049,595,499,932,1015,1130,296,916,849,971,390,1067,1241,971,884,932,0,0,0,349,1223,74,9,1265,0,0,0,1223,349,439,499,877,1078,383,0,22833,18884,32578,34174,52945,30398,39086,21034,43305,0,11048,13315,6645,13694,14848,11048,14749,13315,20850,20850,8,8,82,88,8,8,8,82,82,8,4,4,4,2,4,4,4,4,4,4,8,6,11,1,10,8,8,8,8,10,877,884,977,252,349,1019,390,690,1229,1049,729,595,9,877,1236,439,932,1015,1130,296,916,849,971,390,1067,1241,971,884,932,0,0,0,1223,439,849,584,1078,1049,595,499,349,1223,74,9,1265,0,0,0,1223,349,439,499,877,1078,383,0,332,727,916,1223,877,296,813,971,1223,971,296,276,249,595,1067,412,1223,349,439,584,62,1229,1058,525,4883,11474,9,5,4,4,3,1,2,8,349,62,1223,1178,74,877,385,0,420,1422,4,62,49]]
#
# inputs = torch.LongTensor(inputs)
# print(f"inputs shape {inputs.shape}")


# 1. 从文件读取
with open('profile_features_200.json', 'r', encoding='utf-8') as f:
    loaded_features = json.load(f)  # 类型: List[List[float]]

# 2. 转为 NumPy 数组
inputs = np.array(loaded_features, dtype=np.int32)  # 自动推断形状

inputs = inputs[:64]

inputs = torch.LongTensor(inputs)

# 3. 验证形状
print(inputs.shape)  # 应输出: (200, 1272)


# 将模型和输入移动到相同的设备（例如 GPU）
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)
# inputs = inputs.to(device)

# ----------------------------
# 预热：运行几次推理，让系统“热起来”
# ----------------------------
with torch.no_grad():
    for i in range(10):  # 通常 3~5 次足够
        start = time.time()
        outputs = model(inputs)
        print(f"Run {i+1}: {(time.time() - start)*1000:.2f} ms")
print("Warm-up done.")

# 使用 Profiler 分析性能
with profile(
    # activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],  # 分析 CPU 和 GPU
    activities=[ProfilerActivity.CPU],
    record_shapes=False,  # 记录张量形状
    profile_memory=True,  # 记录内存使用
    with_stack=True,  # 记录调用栈
) as prof:
    for step in range(1):
        with record_function("model_inference"):
            with torch.no_grad():
                outputs = model(inputs)
        prof.step()

# 打印性能分析结果
print(prof.key_averages().table(sort_by="cpu_time_total", row_limit=10))

# 可选：导出分析结果为 Chrome Trace 格式，用于可视化
prof.export_chrome_trace("trace.json")